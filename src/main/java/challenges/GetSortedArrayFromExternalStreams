Question:

Given multiple stream of input numbers,
each of which may not fit in memory (we can assume each source to be individually sorted),
give an API design to merge and store a fully sorted array.

Design must be object oriented which can handle any number of input source types.  Obviously output also cannot fit in memory.

Reference: https://www.careercup.com/question?id=5388826746814464


External merge sort

One example of external sorting is the external merge sort algorithm, which is a K-way merge algorithm.
It sorts chunks that each fit in RAM, then merges the sorted chunks together.

The algorithm first sorts M items at a time and puts the sorted lists back into external memory.
It then recursively does a M/B-way merge on those sorted lists.
To do this merge, B elements from each sorted list are loaded into internal memory, and the minimum is repeatedly outputted.

For example, for sorting 900 megabytes of data using only 100 megabytes of RAM:

    -> Read 100 MB of the data in main memory and sort by some conventional method, like quicksort.
    Write the sorted data to disk.

    -> Repeat steps 1 and 2 until all of the data is in sorted 100 MB chunks (there are 900MB / 100MB = 9 chunks), which now need to be merged into one single output file.

    -> Read the first 10 MB (= 100MB / (9 chunks + 1)) of each sorted chunk into input buffers in main memory and allocate the remaining 10 MB for an output buffer.
    (In practice, it might provide better performance to make the output buffer larger and the input buffers slightly smaller.)

    -> Perform a 9-way merge and store the result in the output buffer. Whenever the output buffer fills, write it to the final sorted file and empty it.

    -> Whenever any of the 9 input buffers empties, fill it with the next 10 MB of its associated 100 MB sorted chunk until no more data from the chunk is available.

    -> This is the key step that makes external merge sort work externally -- because the merge algorithm only makes one pass sequentially through each of the chunks,
    each chunk does not have to be loaded completely; rather, sequential parts of the chunk can be loaded as needed.

Historically, instead of a sort, sometimes a replacement-selection algorithm[3] was used to perform the initial distribution, to produce on average half as many output chunks of double the length.


*****
---- "What if though, you're doing the external sorting and meanwhile you have still numbers coming in from the input streams non-stop?"----
*****

You could maybe use a separate class for each stream. All the classes would be implementing a common interface which has a hasNext and next() function. Now you could have a separate service
which autowires this interface in sort of a list and we loop over it to make a heap.
for (MyStreamInterface stream: streams) {
		if (stream.hasNext()) {
			minHeap.insert(stream.next());
		}
}

similarly you can extract min from the heap and write it to the file.
while (!minMeap.isEmpty()) {
	file.writeInt(minHeap.extractMin())
}

The shared min-heap has to be synchronized as in Producer-Consumer problem.

https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem

The problem describes two processes, the producer and the consumer, who share a common, fixed-size buffer used as a queue.
The producer's job is to generate data, put it into the buffer, and start again.
At the same time, the consumer is consuming the data (i.e., removing it from the buffer), one piece at a time.
The problem is to make sure that the producer won't try to add data into the buffer if it's full and that the consumer won't try to remove data from an empty buffer.




